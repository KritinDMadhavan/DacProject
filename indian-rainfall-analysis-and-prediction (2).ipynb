{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Indian Government has undertaken many research studies to analyze the impact of global warming and climate change on rainfall pattern in India. The analyses were made using observed rainfall data from more than 3000 rain-gauge stations spread over the country for 115 years (1901-2015). The major inferences from these studies based on the 115 years of rainfall data are as follows:\n\n The analysis of 115 years of monsoon rainfall data suggests that there is no long term change or trend in the monsoon rainfall averaged over the country.\n Even though, there are no changes in the all-India rainfall, there are significant changes in annual rainfall in some meteorological sub-divisions. Rainfall over Kerala, East Madhya Pradesh, Jharkhand, Arunachal Pradesh and Nagaland, Manipur, Mizoram and Tripura (NMMT) show decreasing trends. However, rainfall over coastal Karnataka, Maharashtra and Jammu and Kashmir show an increasing trend.\n![](https://krishijagran.com/media/3122/weather-forecast-for-the-week-in-india.png)\n\nThere is a general tendency of increasing frequency of extreme rainfall (heavy rainfall events) over India, especially over the central parts of India during the southwest (June- September) monsoon season.\n There is no evidence of global warming on the observed changes in annual or seasonal rainfall over India. However, there is growing evidence suggesting that increasing frequency of extreme rainfall is due to global warming.\n The climate change assessment made by the Intergovernmental Panel on Climate Change (IPCC) suggest that in future, frequency of extreme rainfall may increase over India due to increase in global warming. However,  there are NO other long term changes/trends in rainfall over India which can be attributed to global warming. The Indian Monsoon is found to be a stable system.\n \n With this data with more variations of average rainfall, it is very difficult for a statistical model to predict the required data point.Here we implement neural networks to predict the avg rainfall, the neural net is used to create multiple features that helps in predicting the data points with more seasonal variations.","metadata":{"_uuid":"5633e580b1cdd6faa78025740076eca6dbeb3aaa"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as py\nimport plotly.offline\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport os\n\nfrom matplotlib import rcParams\nrcParams['figure.figsize']=10,6\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T04:53:26.793901Z","iopub.execute_input":"2022-04-20T04:53:26.794203Z","iopub.status.idle":"2022-04-20T04:53:28.684589Z","shell.execute_reply.started":"2022-04-20T04:53:26.794152Z","shell.execute_reply":"2022-04-20T04:53:28.683663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount(\"/content/drive\")","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-04-20T04:53:28.687604Z","iopub.execute_input":"2022-04-20T04:53:28.687899Z","iopub.status.idle":"2022-04-20T04:53:28.745259Z","shell.execute_reply.started":"2022-04-20T04:53:28.687843Z","shell.execute_reply":"2022-04-20T04:53:28.744308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/content/drive/MyDrive/DAC/rain.csv')\ndf.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = df.groupby('SUBDIVISION')['YEAR','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','NOV','DEC']\ndata=groups.get_group(('TAMIL NADU'))\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.rename(columns = {'SUBDIVISION':'STATE'})","metadata":{"_uuid":"c02d8ece16d770134aa15bc4b7a2177ab2461c9d","execution":{"iopub.status.busy":"2022-04-20T04:53:28.747619Z","iopub.execute_input":"2022-04-20T04:53:28.748517Z","iopub.status.idle":"2022-04-20T04:53:28.801532Z","shell.execute_reply.started":"2022-04-20T04:53:28.747936Z","shell.execute_reply":"2022-04-20T04:53:28.800202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data.melt(['YEAR']).reset_index()\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.lineplot(x = 'YEAR', y= 'ANNUAL', hue = 'STATE', data = df)\nplt.title('Annual Rainfall received',fontsize=20)","metadata":{"_uuid":"ef289be096f4692ec57029aede3d820d799c632c","execution":{"iopub.status.busy":"2022-04-20T04:53:28.80321Z","iopub.execute_input":"2022-04-20T04:53:28.803853Z","iopub.status.idle":"2022-04-20T04:53:28.861871Z","shell.execute_reply.started":"2022-04-20T04:53:28.803793Z","shell.execute_reply":"2022-04-20T04:53:28.860652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\ndf.groupby(['STATE','YEAR'])['ANNUAL'].sum().sort_values(ascending=False).plot()\n\nplt.grid()\nplt.xlabel(\"State,Year\",fontsize=15)\nplt.ylabel(\"Annual Rainfall received\",fontsize=15)\nplt.title('Highest Rainfall year Data of States',fontsize=20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\ndf.groupby(['STATE'])['ANNUAL'].sum().sort_values(ascending=False).head(30).plot(kind='bar', color = 'green')\nplt.ylabel('Total Rainfall')\nplt.title('Total Rainfall Data',fontsize=20)\nplt.grid()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= data[['YEAR','variable','value']].reset_index().sort_values(by=['YEAR','index'])\ndf.head()","metadata":{"_uuid":"8e6f864416f0d543c2cd666c12f0d9fd3b9adf59","execution":{"iopub.status.busy":"2022-04-20T04:53:28.863947Z","iopub.execute_input":"2022-04-20T04:53:28.865692Z","iopub.status.idle":"2022-04-20T04:53:28.9239Z","shell.execute_reply.started":"2022-04-20T04:53:28.865628Z","shell.execute_reply":"2022-04-20T04:53:28.922936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\ndf[['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG','SEP', 'OCT', 'NOV', 'DEC']].mean().plot(kind= 'bar', color='red')\nplt.xlabel('Months',fontsize=15)\nplt.ylabel('Avg. Rainfall',fontsize=15)\nplt.title('Avg. Monthly Rainfall Data',fontsize=25)\nplt.grid()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,2))\ndf[['STATE', 'Jan-Feb', 'Mar-May','Jun-Sep', 'Oct-Dec']].groupby(\"STATE\").mean().sort_values('Jun-Sep').plot.bar(width=0.5,edgecolor='k',align='center',stacked=True,figsize=(16,8))\nplt.xlabel('STATE',fontsize=15)\nplt.ylabel('Rainfall (in mm)',fontsize=15)\nplt.title('Rainfall in States of India',fontsize=25)\nplt.grid()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"YEAR\").mean()['ANNUAL'].plot(ylim=(1000,2000),color='k',marker='o',markerfacecolor='red',linestyle='-',linewidth=2,figsize=(12,10))\nplt.xlabel('Year',fontsize=20)\nplt.ylabel('Annual Rainfall (in mm)',fontsize=20)\nplt.title('Annual Rainfall from  1901 to 2015 in India',fontsize=25)\n\nplt.grid()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns=['INDEX','YEAR','Month','avg_rainfall']\ndf.head()","metadata":{"_uuid":"9791ec325c7934904b50a3a4bdb5e957688d364a","execution":{"iopub.status.busy":"2022-04-20T04:53:28.92543Z","iopub.execute_input":"2022-04-20T04:53:28.926039Z","iopub.status.idle":"2022-04-20T04:53:28.931852Z","shell.execute_reply.started":"2022-04-20T04:53:28.92598Z","shell.execute_reply":"2022-04-20T04:53:28.930926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d={'JAN':1,'FEB':2,'MAR' :3,'APR':4,'MAY':5,'JUN':6,'JUL':7,'AUG':8,'SEP':9,'OCT':10,'NOV':11,'DEC':12}\ndf['Month']=df['Month'].map(d)\ndf.head(12)","metadata":{"_uuid":"1a3874aa6c82b1f154df8852d486113c90de1c98","execution":{"iopub.status.busy":"2022-04-20T04:53:28.95723Z","iopub.execute_input":"2022-04-20T04:53:28.957687Z","iopub.status.idle":"2022-04-20T04:53:28.979419Z","shell.execute_reply.started":"2022-04-20T04:53:28.957643Z","shell.execute_reply":"2022-04-20T04:53:28.978802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Date']=pd.to_datetime(df.assign(Day=1).loc[:,['YEAR','Month','Day']])\ndf.head(12)","metadata":{"_uuid":"5ad293c8a177a44192ae5483f1f0fb7fad91a7c7","execution":{"iopub.status.busy":"2022-04-20T04:53:28.980675Z","iopub.execute_input":"2022-04-20T04:53:28.981097Z","iopub.status.idle":"2022-04-20T04:53:29.094282Z","shell.execute_reply.started":"2022-04-20T04:53:28.981057Z","shell.execute_reply":"2022-04-20T04:53:29.093644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=['avg_rainfall']\ndataset=df[cols]\ndataset.head()","metadata":{"_uuid":"b5922128ec7935d80d550baedc164a238301742a","execution":{"iopub.status.busy":"2022-04-20T04:53:29.095476Z","iopub.execute_input":"2022-04-20T04:53:29.095758Z","iopub.status.idle":"2022-04-20T04:53:29.110194Z","shell.execute_reply.started":"2022-04-20T04:53:29.095707Z","shell.execute_reply":"2022-04-20T04:53:29.109383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series=dataset\nseries.head()","metadata":{"_uuid":"6e7cd0cc309a2ac70207aa51253a47961475657a","execution":{"iopub.status.busy":"2022-04-20T04:53:29.111571Z","iopub.execute_input":"2022-04-20T04:53:29.112085Z","iopub.status.idle":"2022-04-20T04:53:29.126174Z","shell.execute_reply.started":"2022-04-20T04:53:29.112039Z","shell.execute_reply":"2022-04-20T04:53:29.125508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series.shape","metadata":{"_uuid":"52ddfe9326192e481e71e8e15f327b08e97809e5","execution":{"iopub.status.busy":"2022-04-20T04:53:29.127301Z","iopub.execute_input":"2022-04-20T04:53:29.127583Z","iopub.status.idle":"2022-04-20T04:53:29.132873Z","shell.execute_reply.started":"2022-04-20T04:53:29.127527Z","shell.execute_reply":"2022-04-20T04:53:29.132136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pyplot.figure(figsize=(20,6))\npyplot.plot(series.values)\npyplot.show()","metadata":{"_uuid":"fdbca5a9e753a51baa7ed56630603da6cff0f184","execution":{"iopub.status.busy":"2022-04-20T04:53:29.134063Z","iopub.execute_input":"2022-04-20T04:53:29.134596Z","iopub.status.idle":"2022-04-20T04:53:29.665211Z","shell.execute_reply.started":"2022-04-20T04:53:29.134547Z","shell.execute_reply":"2022-04-20T04:53:29.664548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the raw data values from the pandas data frame.\ndata_raw = series.values.astype(\"float32\")\n\n# We apply the MinMax scaler from sklearn\n# to normalize data in the (0, 1) interval.\nscaler = MinMaxScaler(feature_range = (0, 1))\ndataset = scaler.fit_transform(data_raw)\n\n# Print a few values.\ndataset[0:5]","metadata":{"_uuid":"acb8152bf571153ab9605c29ee5006307564f25e","execution":{"iopub.status.busy":"2022-04-20T04:53:29.666171Z","iopub.execute_input":"2022-04-20T04:53:29.666556Z","iopub.status.idle":"2022-04-20T04:53:29.673861Z","shell.execute_reply.started":"2022-04-20T04:53:29.666494Z","shell.execute_reply":"2022-04-20T04:53:29.673067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using 60% of data for training, 40% for validation.\nTRAIN_SIZE = 0.80\n\ntrain_size = int(len(dataset) * TRAIN_SIZE)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\nprint(\"Number of entries (training set, test set): \" + str((len(train), len(test))))","metadata":{"_uuid":"032fe26475a1ce7c2558ae333e8782f9f72a924f","execution":{"iopub.status.busy":"2022-04-20T04:53:29.67499Z","iopub.execute_input":"2022-04-20T04:53:29.675579Z","iopub.status.idle":"2022-04-20T04:53:29.68403Z","shell.execute_reply.started":"2022-04-20T04:53:29.675519Z","shell.execute_reply":"2022-04-20T04:53:29.682912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FIXME: This helper function should be rewritten using numpy's shift function. See below.\ndef create_dataset(dataset, window_size = 1):\n    data_X, data_Y = [], []\n    for i in range(len(dataset) - window_size - 1):\n        a = dataset[i:(i + window_size), 0]\n        data_X.append(a)\n        data_Y.append(dataset[i + window_size, 0])\n    return(np.array(data_X), np.array(data_Y))","metadata":{"_uuid":"4720cf4d3d522ba035c7ea52e8570ab1d0bffdfd","execution":{"iopub.status.busy":"2022-04-20T04:53:29.685698Z","iopub.execute_input":"2022-04-20T04:53:29.686221Z","iopub.status.idle":"2022-04-20T04:53:29.701265Z","shell.execute_reply.started":"2022-04-20T04:53:29.686174Z","shell.execute_reply":"2022-04-20T04:53:29.700058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create test and training sets for one-step-ahead regression.\nwindow_size = 1\ntrain_X, train_Y = create_dataset(train, window_size)\ntest_X, test_Y = create_dataset(test, window_size)\nprint(\"Original training data shape:\")\nprint(train_X.shape)\n\n# Reshape the input data into appropriate form for Keras.\ntrain_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\ntest_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\nprint(\"New training data shape:\")\nprint(train_X.shape)","metadata":{"_uuid":"098a6afdd2add6832bac301974a0d915ca84a622","execution":{"iopub.status.busy":"2022-04-20T04:53:29.702961Z","iopub.execute_input":"2022-04-20T04:53:29.70349Z","iopub.status.idle":"2022-04-20T04:53:29.716809Z","shell.execute_reply.started":"2022-04-20T04:53:29.703415Z","shell.execute_reply":"2022-04-20T04:53:29.715667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_model(train_X, train_Y, window_size = 1):\n    model = Sequential()\n    \n    model.add(LSTM(2000,activation = 'tanh', inner_activation = 'hard_sigmoid', input_shape = (1, window_size)))\n    model.add(Dropout(0.2))\n    model.add(Dense(500))\n    model.add(Dropout(0.4))\n    model.add(Dense(500))\n    model.add(Dropout(0.4))\n    model.add(Dense(400))\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation = 'linear'))\n    model.compile(loss = \"mean_squared_error\", \n                  optimizer = \"adam\")\n    model.fit(train_X, \n              train_Y, \n              epochs = 10, \n              batch_size = 64, \n              )\n    \n    return(model)\n\n# Fit the first model.\nmodel1 = fit_model(train_X, train_Y, window_size)","metadata":{"_uuid":"2fb1715726527302147af221c6213783607345b3","execution":{"iopub.status.busy":"2022-04-20T04:53:29.718199Z","iopub.execute_input":"2022-04-20T04:53:29.718751Z","iopub.status.idle":"2022-04-20T04:55:03.920811Z","shell.execute_reply.started":"2022-04-20T04:53:29.718693Z","shell.execute_reply":"2022-04-20T04:55:03.920075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\ndef predict_and_score(model, X, Y):\n    # Make predictions on the original scale of the data.\n    pred = scaler.inverse_transform(model.predict(X))\n    # Prepare Y data to also be on the original scale for interpretability.\n    orig_data = scaler.inverse_transform([Y])\n    # Calculate RMSE.\n    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n    return(score, pred)\n\nrmse_train, train_predict = predict_and_score(model1, train_X, train_Y)\nrmse_test, test_predict = predict_and_score(model1, test_X, test_Y)\n\nprint(\"Training data score: %.2f RMSE\" % rmse_train)\nprint(\"Test data score: %.2f RMSE\" % rmse_test)","metadata":{"_uuid":"8b146015fb5951241bfdb671476fb491c91798dd","execution":{"iopub.status.busy":"2022-04-20T04:55:03.921805Z","iopub.execute_input":"2022-04-20T04:55:03.922119Z","iopub.status.idle":"2022-04-20T04:55:05.332664Z","shell.execute_reply.started":"2022-04-20T04:55:03.922076Z","shell.execute_reply":"2022-04-20T04:55:05.331888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start with training predictions.\ntrain_predict_plot = np.empty_like(dataset)\ntrain_predict_plot[:, :] = np.nan\ntrain_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n\n# Add test predictions.\ntest_predict_plot = np.empty_like(dataset)\ntest_predict_plot[:, :] = np.nan\ntest_predict_plot[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict\n\n# Create the plot.\nplt.figure(figsize = (18, 8))\nplt.plot(scaler.inverse_transform(dataset), label = \"True value\",color='red')\nplt.plot(train_predict_plot, label = \"Training set prediction\",color='yellow')\nplt.plot(test_predict_plot, label = \"Test set prediction\")\nplt.xlabel(\"Months\")\n\n\nplt.legend()\nplt.show()","metadata":{"_uuid":"923d86b0c949c8a93597929997cc3dcc593d4398","execution":{"iopub.status.busy":"2022-04-20T04:55:05.333688Z","iopub.execute_input":"2022-04-20T04:55:05.333949Z","iopub.status.idle":"2022-04-20T04:55:05.912983Z","shell.execute_reply.started":"2022-04-20T04:55:05.333899Z","shell.execute_reply":"2022-04-20T04:55:05.911969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict","metadata":{"_uuid":"96494806f8197b83853e34834f40455d10a416da","execution":{"iopub.status.busy":"2022-04-20T04:55:05.914719Z","iopub.execute_input":"2022-04-20T04:55:05.915061Z","iopub.status.idle":"2022-04-20T04:55:05.926897Z","shell.execute_reply.started":"2022-04-20T04:55:05.915006Z","shell.execute_reply":"2022-04-20T04:55:05.926012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predict","metadata":{"_uuid":"f17eb5416d4925ea69b12330170fc3dba4a0e7dc","execution":{"iopub.status.busy":"2022-04-20T04:55:05.928002Z","iopub.execute_input":"2022-04-20T04:55:05.928684Z","iopub.status.idle":"2022-04-20T04:55:05.935681Z","shell.execute_reply.started":"2022-04-20T04:55:05.928218Z","shell.execute_reply":"2022-04-20T04:55:05.934756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"aae24aabede991e13d9cc1c7dd28bce7d99188c9","trusted":true},"execution_count":null,"outputs":[]}]}